{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yuiTjhaQf5aXPEJqo0qhF39itHsNP1__",
      "authorship_tag": "ABX9TyO8qHca9VbFUEJidjwlxCe/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meirarc/Market_Price/blob/main/Market_Price.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Market Price Web Scraping"
      ],
      "metadata": {
        "id": "Qt-9IQr-BsdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Web Scrapping\n",
        "\n",
        "Price scraping is rising with the growing competition and growth in online marketplaces. A new player in the market can quickly get up to speed using price and content scraping services. This is because when scraper bots attack a website, they potentially gain access to information on Stock Keeping Units (SKU), product listings, historical pricing, and their entire product catalog. This breadth of information can give new rivals a huge competitive edge. Competitors can automate their scraping activity to such an extent that their website automatically reflects the best price upon analyzing prices from competing sites.\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "PQyOZCUuUi4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### However, it´s not possible to scrape all the data with website APIs.\n",
        "Some websites provide APIs for users to access part of their data. But even though these sites provide APIs, there still exist some data fields that can´t scrape or have no authentication to access.\n",
        "\n",
        "For example, Amazon provides a Product Advertising API, but the API itself couldn’t provide access to all the information displayed on its product page for people to scrape, like price and others. In this case, the only way to scrape more data, saying the price data field, is to build our scraper by programming or using certain kinds of automated scraper tools.\n",
        " \n",
        "### It is hard to get the correct data, even for programmers.\n",
        "Sometimes, even if we know how to scrape data on our own by programming, like the example below in Python, we still could not scrape data successfully for various reasons. In most cases, we probably would be forbidden to scrape from certain websites due to our suspicious repeating scraping actions within a short time. \n",
        "\n",
        "### Why I started this project\n",
        "Consumers nowadays are constantly looking for discounts, special offers, and comparing prices in different online businesses. I started this project for personal use and to help me in a very specific scenario where I usually compare the prices between multiple websites and make a decision on where I will buy the products. This was a weekly activity and manual. \n",
        "\n",
        "To improve the work and study a little bit more about data manipulation, data analysis, etc, I tested this model to scrap data from the web and help to increase much time on my weekly activity. It would be best if the website is up to date on pricing and if all the markets allow you to scrap the data, but this is not the case and this entire automation is used today for a learning perspective and try to solve many different problems on the way."
      ],
      "metadata": {
        "id": "8YmOeAOpUqo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries for data exploration, processing, and web scraping\n",
        "\n",
        "We need to import a couple of Python libraries that we will need for data exploration, processing, visualization, and web scraping.\n",
        "\n",
        "- **Pandas** — We will be using pandas data frames for their functions and a tabular representation of our dataset.\n",
        "\n",
        "- **BeautifulSoup** — For parsing HTML and XML documents. We will be using this library for web scraping.\n",
        "\n",
        "- **requests**- To download the web page in HMTL format.\n",
        "\n",
        "- **re** - Work with Regular Expressions\n",
        "\n",
        "- **json** - Convert string to json obejct\n",
        "\n",
        "We will be working in the Google Colab for this tutorial, but you are welcome to use a Python IDE of your choice.\n",
        "\n",
        "Additionally, we are using the **print_function** library and redefined the work for the **print** command to improve the logging and debugging on the Google Colab.\n"
      ],
      "metadata": {
        "id": "27Goqz3rCMqH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lmSxBr8Y56z"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set some reusable parameters\n",
        "\n",
        "The following parameters are reusable in the processes. \n",
        "- `enable_print` - log the print when this parameter is `True`\n",
        "- `filename` - import and export the CSV data with the Product and the prices after web scrapping."
      ],
      "metadata": {
        "id": "lVqd8AzPCn5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enable_print = False\n",
        "filename = \"/content/drive/MyDrive/Colab/Market_Price.csv\""
      ],
      "metadata": {
        "id": "R0C_uRSe4PSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defined the functions\n",
        "\n",
        "At this point we are working with two types of functions:\n",
        "- Utility functions -  can be easily copied for other projects without changes based on the use.\n",
        "- Custom-Specific functions - Necessary to update the code, and logic, and these functions are very specific to solve/get the requirement completed."
      ],
      "metadata": {
        "id": "-zJ0jB-ACvwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities Functions"
      ],
      "metadata": {
        "id": "UUpSLaQqC0C1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### print functoin\n",
        "If the parameter `enable_print` is `True` the `print` will be used to log information and help to debug the application."
      ],
      "metadata": {
        "id": "LYtZDtAuKAT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print(*args, **kwargs):\n",
        "  if enable_print:\n",
        "    return __builtins__.print(*args, **kwargs)"
      ],
      "metadata": {
        "id": "hdMVz0oGLXW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### compare_price\n",
        "this function just compares two prices and provides status about the comparison"
      ],
      "metadata": {
        "id": "l8dbgiAYKXs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_price(current, new):\n",
        "  print(\"(compare_price): current: \",current, \" is blank: \", current == \"\")\n",
        "  print(\"(compare_price): new: \", new, \" is blank: \", new == \"\")\n",
        "  print(\"(compare_price:) \",current, new)\n",
        "\n",
        "  current = float(str(current).replace(\",\",\".\")) if current != \"\" and current is not None else 0 \n",
        "  new = float(str(new).replace(\",\",\".\")) if new != \"\" and new is not None else 0\n",
        "\n",
        "  status = \"\"\n",
        "  status = \"Same Price\" if new == current else status  \n",
        "  status = \"More Expensive\" if new > current else status   \n",
        "  status = \"On Sale\" if new < current else status\n",
        "  return status"
      ],
      "metadata": {
        "id": "HZ07a-XQ_9WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom-Specific Functions per Market\n"
      ],
      "metadata": {
        "id": "DJjZTk3hC7q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### St. Marche"
      ],
      "metadata": {
        "id": "y_1Q_MA3DDy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def marche(item):\n",
        "    webpage = requests.get(item[\"URL\"])\n",
        "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
        "    info = soup.find(attrs={\"class\":\"name-and-info\"}).p.get_text()\n",
        "    \n",
        "    product_name = soup.find(attrs={\"class\":\"product-name\"}).get_text()\n",
        "    product_price = float(info.split(\"R$ \",1)[1].split(\"/\",1)[0].replace(\",\",\".\"))\n",
        "    product_unit = info.split(\"R$ \",1)[1].split(\"/\",1)[1]\n",
        "\n",
        "    if product_unit.strip() == \"kg\":\n",
        "      size = \"1\"\n",
        "      price_kg = product_price\n",
        "    else:\n",
        "      size = product_name.split(\" \")[-1]\n",
        "      if size[-1] == \"g\":\n",
        "        size = float(size.replace(\"g\", \"\"))/1000\n",
        "        price_kg = round(product_price/size, 2)\n",
        "        product_unit = \"g\"\n",
        "      else:\n",
        "        if product_unit.strip() == \"un\":\n",
        "          size = \"3\"\n",
        "          price_kg = product_price * 3\n",
        "        else:\n",
        "          size = \"\"\n",
        "          price_kg = \"\"\n",
        "\n",
        "    status = compare_price(item[\"Product Price per Kg\"], price_kg)\n",
        "    \n",
        "    item[\"Product Name\"] = product_name if product_name is not None else \"\"\n",
        "    item[\"Product Price\"] = \"{:.2f}\".format(product_price) if product_price is not None else \"\"\n",
        "    item[\"Product Unit\"] = product_unit if product_unit is not None else \"\"\n",
        "    item[\"Product Size\"] = \"{:.3f}\".format(float(size)) if size is not None else \"\"\n",
        "    item[\"Product Price per Kg\"] = \"{:.2f}\".format(price_kg) if price_kg is not None else \"\"\n",
        "    item[\"Status\"] = status if status is not None else \"\"\n",
        "\n",
        "    return item"
      ],
      "metadata": {
        "id": "363fwqddd8LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Oba\n",
        "**To-do**\n",
        "- [ ] Fix the web scrapping for this page - I´m facing some challenges in web scrapping this marketplace. "
      ],
      "metadata": {
        "id": "82ZPsLLzDHRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def oba(item):\n",
        "\n",
        "  headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\"}\n",
        "  webpage = requests.get(item[\"URL\"], headers=headers)\n",
        "  soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
        "  \n",
        "  product_name = \"\"\n",
        "  product_price = \"\"\n",
        "  product_unit = \"\"\n",
        "  size = \"\"\n",
        "  price_kg = \"\"\n",
        "\n",
        "  product_name = soup.find(attrs={\"class\":re.compile(\"ProductDetailsStyles\")})\n",
        "  product_name = product_name if product_name is not None else \"\"\n",
        "  \n",
        "  product_price = soup.find(attrs={\"class\":re.compile(\"ProductDetailsStyles\")})\n",
        "  product_price = product_price if product_price is not None else \"\"\n",
        "  \n",
        "  product_unit = \"\"\n",
        "\n",
        "  status = compare_price(item[\"Product Price per Kg\"], price_kg)\n",
        "\n",
        "  item[\"Product Name\"] = product_name if product_name is not None else \"\"\n",
        "  item[\"Product Price\"] = product_price if product_price is not None else \"\"\n",
        "  item[\"Product Unit\"] = product_unit if product_unit is not None else \"\"\n",
        "  item[\"Product Size\"] = size if size is not None else \"\"\n",
        "  item[\"Product Price per Kg\"] = price_kg if price_kg is not None else \"\"\n",
        "  item[\"Status\"] = status if status is not None else \"\"\n",
        "  \n",
        "  return item"
      ],
      "metadata": {
        "id": "ewn481z9km08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hakuo\n",
        "**To-do**\n",
        "- [ ] Fix the web scrapping for this page - I´m facing some challenges in web scrapping this marketplace."
      ],
      "metadata": {
        "id": "IaFDmhXNFbD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hakuo(item):\n",
        "  \n",
        "  headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\"}\n",
        "  webpage = requests.get(item[\"URL\"], headers=headers)\n",
        "  soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
        "  \n",
        "  product_name = \"\"\n",
        "  product_price = \"\"\n",
        "  product_unit = \"\"\n",
        "  size = \"\"\n",
        "  price_kg = \"\"\n",
        "\n",
        "  product_name = item[\"URL\"].split(\"/\")[-1].replace(\"-\", \" \")\n",
        "  product_name = product_name if product_name is not None else \"\"\n",
        "  \n",
        "  product_price = soup.find(attrs={\"class\":re.compile(\"area-preco-detalhe-produto\")})\n",
        "  print(product_price)\n",
        "  product_price = product_price if product_price is not None else \"\"\n",
        "  \n",
        "  product_unit = \"\"\n",
        "\n",
        "  status = compare_price(item[\"Product Price per Kg\"], price_kg)\n",
        "\n",
        "  item[\"Product Name\"] = product_name if product_name is not None else \"\"\n",
        "  item[\"Product Price\"] = product_price if product_price is not None else \"\"\n",
        "  item[\"Product Unit\"] = product_unit if product_unit is not None else \"\"\n",
        "  item[\"Product Size\"] = size if size is not None else \"\"\n",
        "  item[\"Product Price per Kg\"] = price_kg if price_kg is not None else \"\"\n",
        "  item[\"Status\"] = status if status is not None else \"\"\n",
        "  \n",
        "  return item"
      ],
      "metadata": {
        "id": "SMcfOmh_8iPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sams Club"
      ],
      "metadata": {
        "id": "bO33_nckF5TA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sams(item):\n",
        "  headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\"}\n",
        "  webpage = requests.get(item[\"URL\"], headers=headers)\n",
        "  soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
        "  \n",
        "  product_name = soup.find(attrs={\"class\":re.compile(\"productBrand\")})\n",
        "  product_name = product_name.get_text().strip() if product_name is not None else \"Error Product Name\"\n",
        "  print(\"(sams) product_name: \",product_name)\n",
        "\n",
        "  product_price  = soup.find(attrs={\"class\":re.compile(\"productShowCasePricePdp\")})\n",
        "  product_price_kg  = soup.find(attrs={\"class\":re.compile(\"productShowCasePriceKgPdp\")})\n",
        "  \n",
        "  price_kg = 0\n",
        "  price = 0\n",
        "  unit = \"\"\n",
        "  \n",
        "  if product_price_kg is not None:\n",
        "    clean_price_kg = product_price_kg.get_text().strip()\n",
        "    if clean_price_kg != \"\":\n",
        "      price_kg = clean_price_kg.split(\" \")[-1].replace(u'\\xa0', ' ').split(\"$\")[-1].replace(\",\",\".\").strip()\n",
        "      unit = clean_price_kg.split(\" \")[0]\n",
        "  print(\"(sams) price_kg: \",price_kg)\n",
        "  print(\"(sams) unit: \",unit)\n",
        "\n",
        "  if product_price is not None:\n",
        "    clean_price = product_price.get_text().strip()\n",
        "    if clean_price != \"\":\n",
        "      price = clean_price.split(\"$\")[-1].replace(\",\",\".\").strip()\n",
        "  print(\"(sams) price: \",price)\n",
        "\n",
        "  product_price = price_kg if price_kg != 0 else price\n",
        "  product_price = product_price if product_price is not None else \"\"\n",
        "  print(\"(sams) product_price: \",product_price)\n",
        "\n",
        "  product_unit = unit if unit != \"\" else \"\"\n",
        "  product_unit = product_unit if product_unit is not None else \"\"\n",
        "  print(\"(sams) product_unit: \", product_unit)\n",
        "\n",
        "    \n",
        "  if product_unit.strip() == \"Preço/Kg\":\n",
        "    size = \"1\"\n",
        "    price_kg = product_price\n",
        "    product_unit = \"kg\"\n",
        "  else:\n",
        "    unit = product_name.strip().split(\" \")[-1]\n",
        "    product_unit = unit\n",
        "    \n",
        "    if product_unit == \"Unidade\":\n",
        "      size = \"3\"\n",
        "      price_kg = \"{:.2f}\".format(float(product_price) * 3) if product_price != \"\" else \"\"\n",
        "      product_unit = \"un\" \n",
        "    else:\n",
        "      if product_unit[-2:].lower() == \"kg\": \n",
        "        size = product_unit[:-2].replace(\",\", \".\")\n",
        "        price_kg = round(float(product_price) / float(size), 2)\n",
        "        product_unit = \"kg\"\n",
        "      else:\n",
        "        print(product_unit)\n",
        "        if product_unit.strip()[-1].lower() == \"g\": \n",
        "          size = float(product_unit[:-1])/1000\n",
        "          price_kg = float(product_price) / size if product_price != \"\" else \"\"\n",
        "          product_unit = \"g\"\n",
        "        else:\n",
        "          if product_name.strip() == \"Batata Pacote\":\n",
        "              size = \"2\"\n",
        "              price_kg = float(product_price) / 2\n",
        "              product_unit = \"kg\"\n",
        "          else:\n",
        "            if product_name.strip() == \"Agrião Verdureira\":\n",
        "              size = \"3\"\n",
        "              price_kg = float(product_price) * 2\n",
        "              product_unit = \"un\"\n",
        "            else:\n",
        "              size = \"\"\n",
        "              price_kg = \"\"\n",
        "              product_unit = \"\"\n",
        "\n",
        "  print(\"(sams) current, item[Product Price per Kg]: \", item[\"Product Price per Kg\"] == \"\")\n",
        "  print(\"(sams) new, price_kg: \", price_kg)\n",
        "  status = compare_price(item[\"Product Price per Kg\"], price_kg)\n",
        "\n",
        "  item[\"Product Name\"] = product_name if product_name is not None else \"\"\n",
        "  item[\"Product Price\"] = product_price if product_price is not None else \"\"\n",
        "  item[\"Product Unit\"] = product_unit if product_unit is not None else \"\"\n",
        "  item[\"Product Size\"] = size if size is not None else \"\"\n",
        "  item[\"Product Price per Kg\"] = price_kg if price_kg is not None else \"\"\n",
        "  item[\"Status\"] = status if status is not None else \"\"\n",
        "\n",
        "  return item"
      ],
      "metadata": {
        "id": "I_fmxubggQCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pão de Açucar"
      ],
      "metadata": {
        "id": "5rGcOxCGF8-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def paodeacucar(item):\n",
        "\n",
        "  headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\"}\n",
        "  webpage = requests.get(item[\"URL\"], headers=headers)\n",
        "  soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
        "  \n",
        "  product_name = soup.find(attrs={\"class\":\"textstyles__TextComponent-w4b5ef-0 iISkjF\"}).get_text().strip()\n",
        "  product_unit = \"\"\n",
        "  size = product_name.split(\" \")[-1]\n",
        "\n",
        "  product_price = soup.find(attrs={\"class\":re.compile(\"CurrentPrice\")})\n",
        "  product_price = float(product_price.p.get_text().split(\"R$ \",1)[1].replace(\",\",\".\")) if product_price is not None else \"\"\n",
        "\n",
        "\n",
        "  if size[-2].lower() == \"k\":\n",
        "    size = float(size.lower().replace(\"kg\", \"\").replace(\",\",\".\"))\n",
        "    price_kg = round(product_price/size, 2) if product_price != \"\" else \"\"\n",
        "    product_unit = \"kg\"\n",
        "  else: \n",
        "    if size[-1] == \"g\":\n",
        "      size = float(size.replace(\"g\", \"\"))\n",
        "      price_kg = round(product_price/size*1000, 2) if product_price != \"\" else \"\"\n",
        "      product_unit = \"g\"\n",
        "    else:\n",
        "      size = \"3\"\n",
        "      product_unit = \"un\"\n",
        "      price_kg = product_price * 3\n",
        "\n",
        "  status = compare_price(item[\"Product Price per Kg\"], price_kg)\n",
        "\n",
        "  item[\"Product Name\"] = product_name if product_name is not None else \"\"\n",
        "  item[\"Product Price\"] = product_price if product_price is not None else \"\"\n",
        "  item[\"Product Unit\"] = product_unit if product_unit is not None else \"\"\n",
        "  item[\"Product Size\"] = size if size is not None else \"\"\n",
        "  item[\"Product Price per Kg\"] = price_kg if price_kg is not None else \"\"\n",
        "  item[\"Status\"] = status if status is not None else \"\"\n",
        "\n",
        "  return item"
      ],
      "metadata": {
        "id": "xG-LkPWXX3aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and work with CSV data\n",
        "\n",
        "Now, after the import of the main libraries and defining the functions, the next step is to work with the data. \n",
        "\n",
        "To easily store the data somewhere that can be used for offline manipulation in Excel the decision was to use Google Drive to store a CSV."
      ],
      "metadata": {
        "id": "lAp5EXWWGBHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fix the Prices format \n",
        "Due to Excel formation for localization currencies, I had to perform some string manipulation before starting to work with the data on JSON objects. Doing this manipulation before creating the JSON object avoids manipulating the data many times under the custom-specifics functions."
      ],
      "metadata": {
        "id": "5MUYfQ1CGxeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(filename, sep=\";\", encoding = \"utf-8\")\n",
        "df[\"Product Price per Kg\"] = df[\"Product Price per Kg\"].str.replace(\",\",\".\")\n",
        "df[\"Product Price\"] = df[\"Product Price\"].str.replace(\",\",\".\")\n",
        "df[\"Product\"] = df[\"Product\"].str.replace(u'\\xa0', u' ')\n",
        "df = df.fillna(\"\")\n",
        "df"
      ],
      "metadata": {
        "id": "x1FknIYXe9n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with JSON objects\n",
        "After all the manipulations were completed in the previous step we are good to create the JSON objects and easily work with the data. \n",
        "\n",
        "**To-do**\n",
        "- [ ] perform additional data manipulations before creating the JSON objects and remove the data manipulation from the custom-specific functions"
      ],
      "metadata": {
        "id": "PgaO-Js3G8Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = df.to_json(orient = 'records')\n",
        "data = json.loads(string)"
      ],
      "metadata": {
        "id": "TsWtHq-XmQK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterate each record line\n",
        "For each record, the CVS/JSON checks if it has the URL to perform the request and calls the market specif function to extract the `product name`, `price`, `size`, etc."
      ],
      "metadata": {
        "id": "xWa0N7_RHGwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for item in data:\n",
        "  if item[\"URL\"] is not None and item[\"URL\"] != \"\":\n",
        "    marche(item) if item[\"Market\"] == \"St. Marche\" else None\n",
        "    sams(item) if item[\"Market\"] == \"Sams Club\" else None\n",
        "    paodeacucar(item) if item[\"Market\"] == \"Pao de Acucar\" else None\n",
        "    #oba(item) if item[\"Market\"] == \"Oba\" else None\n",
        "    #hakuo(item) if item[\"Market\"] == \"Hakuo\" else None"
      ],
      "metadata": {
        "id": "mJVXg2Z9O185"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update the Data Frame and Export the Data\n",
        "The JSON object `data` is getting updated from the market-specific functions with `price`, `size`, etc. At this time we are converting back the JSON object to Pandas DataFrame and updating the original DataFrame with the new data."
      ],
      "metadata": {
        "id": "bQ_6q2spHXSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.DataFrame(data)\n",
        "data_df"
      ],
      "metadata": {
        "id": "CgonkX43fl0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.update(data_df)\n",
        "df"
      ],
      "metadata": {
        "id": "O9HUT_OF_DEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Export the data for a local Excel data manipulation\n",
        "By using the same Google Drive integration with the previous CSV file, now we are updating the file with new data. Using the same file we can compare the old prices and set some status for each record."
      ],
      "metadata": {
        "id": "HtWtClUYHgnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(filename, index=False, sep=\";\", encoding = \"utf-8\")"
      ],
      "metadata": {
        "id": "9pv-HfWzOVB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data classification and visualization\n",
        "\n",
        "The first data visualization is related to *On Sale* products ordered by *Market*\n",
        "\n",
        "**To-do**\n",
        "- [ ] Planning to add more data visualization in future"
      ],
      "metadata": {
        "id": "ATpPYvKdHezs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(by=[\"Market\"]).query(\"Status == 'On Sale'\")"
      ],
      "metadata": {
        "id": "odblrTAVOW_C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}